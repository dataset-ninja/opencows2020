The authors of the **OpenCows2020** dataset undertook a study focused on Holstein-Friesian cattle, which are known for their distinct black and white coat patterns resembling those generated by Turing's reaction-diffusion systems. Their research aimed to automate the visual detection and biometric identification of individual Holstein-Friesian cattle using convolutional neural networks and deep metric learning techniques. This approach was conceived as an alternative to existing methods that rely on physical markings, tags, or wearables, all of which have varying maintenance requirements.

In the study, the authors introduced an entirely hands-off method for the automated detection, localization, and identification of individual cattle from overhead imagery, even in open herd settings where new additions to the herd could be identified without the need for retraining the system. Their findings indicated that deep metric learning systems exhibited robust performance, achieving an accuracy of 93.8% when trained on only half of the cattle population.

<img src="https://github.com/supervisely/supervisely/assets/78355358/403d9387-b3b0-4e39-a6db-3fc982922619" alt="image" width="800">

Traditional methods of traceability involve national tracking databases and unique ear-tag identification, injectable transponders, branding, and more. However, these methods are limited in providing continuous localization of individuals, which is crucial for applications in precision farming and various research areas.

To address this limitation, the authors proposed leveraging the inherent and characteristic coat patterns of Holstein-Friesian cattle for non-intrusive visual identification, laying the foundation for continuous monitoring of herds on an individual level through non-intrusive visual observation.

The study delineated two scenarios: `<i>`closed-set identification`</i>`, where the system is trained and tested on a fixed set of known cattle, and `<i>`open-set identification`</i>`, where the system should identify cattle that have never been seen before without retraining. They presented a comprehensive pipeline for detection and open-set recognition, allowing for the flexible identification of individual cattle in real-world scenarios.

The OpenCows2020 dataset includes indoor and outdoor top-down imagery for cattle detection, localization, and open-set identification. The dataset comprised a total of 3,707 ***non-synthetic*** and 3336 augmented ***synthetic*** images. For open-set identification, they included 46 individuals with an average of 103 instances per class and 4,736 regions overall. The dataset was carefully split into training, validation, and testing sets to support 10-fold 8:1:1 cross-validation. Download [original dataset](https://data.bris.ac.uk/data/dataset/10m32xl88x2b61zlkkgz3fml17) to get detailed info about cross-validation.

<img src="https://github.com/supervisely/supervisely/assets/78355358/f130d4bd-1088-4180-b61b-8c7ef3f8337c" alt="image" width="800">

<span style="font-size: smaller; font-style: italic;">Identification Instance Distribution. The distribution of instances per class for the identification component of the OpenCows2020 dataset. Instances were then randomly split to have exactly 10 testing instances per class whilst those remaining were split into training and validation in a ratio of 9 : 1, respectively. Also labelled is the source of each group of categories. ( a ), ( b ) and ( c )</span>

Their work aimed to advance non-intrusive monitoring of cattle, applicable to precision farming, automated productivity assessment, health and welfare monitoring, and veterinary research, including behavioral analysis and disease outbreak tracing.
